{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37364bit84282b17c8fc49e4b6d1a77ddc584f5a",
   "display_name": "Python 3.7.3 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "e100df3301a6055e66e482bedc0544ab8172cad21974fa73230a16a53ea8b9c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## packages"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from collections import Counter\n",
    "import math"
   ]
  },
  {
   "source": [
    "## data\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict={'M':1,'S':2,'L':3}\n",
    "def creat_data():\n",
    "    df=pd.read_csv('./c3_data.csv')\n",
    "    data=np.array(df)\n",
    "    X,y=data[:,:-1],data[:,-1]\n",
    "    # print(X,y)\n",
    "    for x in X:\n",
    "        x[1]=dict[x[1]]\n",
    "    return  X.astype(np.int64),y.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([[1, 1],\n",
       "        [1, 1],\n",
       "        [1, 2],\n",
       "        [1, 2],\n",
       "        [2, 2],\n",
       "        [2, 1],\n",
       "        [2, 1],\n",
       "        [2, 3],\n",
       "        [2, 3],\n",
       "        [3, 3],\n",
       "        [3, 1],\n",
       "        [3, 1],\n",
       "        [3, 3],\n",
       "        [3, 3]], dtype=int64),\n",
       " array([-1,  1,  1, -1, -1, -1,  1,  1,  1,  1,  1,  1,  1, -1],\n",
       "       dtype=int64))"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "X,y=creat_data()\n",
    "X,y\n",
    "# print(X,y)"
   ]
  },
  {
   "source": [
    "## sklearn"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=creat_data()\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "X_train,y_train=X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([1, 1], dtype=int64), -1)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "X_train[0], y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "clf.predict([[2,dict['S']]])"
   ]
  },
  {
   "source": [
    "## Naive"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train=creat_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{-1: [[1, 1], [1, 2], [2, 2], [2, 1], [3, 3]], 1: [[1, 1], [1, 2], [2, 1], [2, 3], [2, 3], [3, 3], [3, 1], [3, 1], [3, 3]]}\n"
     ]
    }
   ],
   "source": [
    "# seperate_by_class():\n",
    "seperated_date={}\n",
    "for value,label in zip(X_train.tolist(),y_train.tolist()):\n",
    "    if label not in seperated_date:\n",
    "        seperated_date[label]=[]\n",
    "    seperated_date[label].append(value)\n",
    "print(seperated_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{-1: 0.35714285714285715, 1: 0.6428571428571429}\n"
     ]
    }
   ],
   "source": [
    "#p_label_calucate()\n",
    "p_label={}\n",
    "for i in seperated_date:\n",
    "    # print(len(seperated_date[i]))\n",
    "    p_label[i]=len(seperated_date[i])/len(X_train)\n",
    "print(p_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 代码可读性非常的重要。直接决定了寿命。如何写出呢？多写多读。写了让别人读，读别人的好的地方要借鉴。\n",
    "# 不要为了酷炫牺牲可读性。不要投机取巧。\n",
    "# 必须要做模块化，非常重要，人脑是技巧。\n",
    "## 模块之前不要实现循环依赖。形成偏序集。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary_label:calculate the condition probility\n",
    "def summary_label(value):\n",
    "    a=[]\n",
    "    for column in zip(*value):\n",
    "        column=list(column)\n",
    "        p_value={}\n",
    "        for i in set(column):\n",
    "            p_value[i]=column.count(i)/len(value)\n",
    "        a.append(p_value.copy())\n",
    "    return a.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{-1: [{1: 0.4, 2: 0.4, 3: 0.2}, {1: 0.4, 2: 0.4, 3: 0.2}],\n",
       " 1: [{1: 0.2222222222222222, 2: 0.3333333333333333, 3: 0.4444444444444444},\n",
       "  {1: 0.4444444444444444, 2: 0.1111111111111111, 3: 0.4444444444444444}]}"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "## calculate_p_value\n",
    "p_value={label:summary_label(value) for label,value in seperated_date.items()}\n",
    "p_value\n",
    "    "
   ]
  },
  {
   "source": [
    "### predict"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "x=[3,dict['S']]\n",
    "max_label=0\n",
    "max_p=0\n",
    "for label in p_label:\n",
    "    p=p_label[label]\n",
    "    for i in range(len(x)):\n",
    "        p=p*p_value[label][i][x[i]]\n",
    "    if max_p<p:\n",
    "        max_p=p\n",
    "        max_label=label\n",
    "max_label"
   ]
  },
  {
   "source": [
    "relfection:\n",
    "* .this algorithm must make sure that every kind of instance occurs in the data of training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 使用class进行存储"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train=creat_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model:\n",
    "    def __init__(self):\n",
    "        self.p_label={}\n",
    "        self.p_value={}\n",
    "    def seperate_by_class(self,X_train,y_train):\n",
    "        seperated_date={}\n",
    "        for value,label in zip(X_train.tolist(),y_train.tolist()):\n",
    "            if label not in seperated_date:\n",
    "                seperated_date[label]=[]\n",
    "            seperated_date[label].append(value)\n",
    "        return seperated_date\n",
    "    def p_label_calucate(self,seperated_date):\n",
    "        p_label={}\n",
    "        for i in seperated_date:\n",
    "            p_label[i]=len(seperated_date[i])/len(X_train)\n",
    "        return p_label\n",
    "\n",
    "        # summary_label:calculate the condition probility\n",
    "    def summary_label(self,value):\n",
    "        a=[]\n",
    "        for column in zip(*value):\n",
    "            column=list(column)\n",
    "            p_value={}\n",
    "            for i in set(column):\n",
    "                p_value[i]=column.count(i)/len(value)\n",
    "            a.append(p_value.copy())\n",
    "        return a.copy()\n",
    "\n",
    "    def calculate_p_value(self,seperated_date):\n",
    "        p_value={label:self.summary_label(value) for label,value in seperated_date.items()}\n",
    "        return p_value\n",
    "\n",
    "    def train(self,X_train,y_train):\n",
    "        seperated_date=self.seperate_by_class(X_train,y_train)\n",
    "        self.p_label=self.p_label_calucate(seperated_date)\n",
    "        self.p_value=self.calculate_p_value(seperated_date)\n",
    "    \n",
    "    def predict(self,x):\n",
    "        p_label=self.p_label\n",
    "        p_value=self.p_value\n",
    "        max_label=0\n",
    "        max_p=0\n",
    "        for label in p_label:\n",
    "            p=p_label[label]\n",
    "            for i in range(len(x)):\n",
    "                p=p*p_value[label][i][x[i]]\n",
    "            if max_p<p:\n",
    "                max_p=p\n",
    "                max_label=label\n",
    "        print(max_label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "naiveByes=model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "naiveByes.train(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "naiveByes.predict([3,dict['S']])"
   ]
  },
  {
   "source": [
    "## 贝叶斯估计\n",
    "加上拉普拉斯平滑（Laplacian smoothing)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_lam:\n",
    "    def __init__(self,lam=1): # lambda >0\n",
    "        self.p_label={}\n",
    "        self.p_value={}\n",
    "        self.lam=lam\n",
    "\n",
    "    def seperate_by_class(self,X_train,y_train):\n",
    "        seperated_date={}\n",
    "        for value,label in zip(X_train.tolist(),y_train.tolist()):\n",
    "            if label not in seperated_date:\n",
    "                seperated_date[label]=[]\n",
    "            seperated_date[label].append(value)\n",
    "        return seperated_date\n",
    "    def p_label_calucate(self,seperated_date,X_train):\n",
    "        p_label={}\n",
    "        for i in seperated_date:\n",
    "            p_label[i]=len(seperated_date[i]+self.lam)/(len(X_train)+len(seperated_date)*self.lam)  ## add the lambda  \n",
    "        return p_label\n",
    "\n",
    "        # summary_label:calculate the condition probility\n",
    "    def summary_label(self,value):\n",
    "        a=[]\n",
    "        for column in zip(*value):\n",
    "            column=list(column)\n",
    "            p_value={}\n",
    "            a=set(column)\n",
    "            Sj=len(a)\n",
    "            for i in a:\n",
    "                p_value[i]=(self.lam+column.count(i))/(len(value)+self.lam+Sj)  ## add the lambda \n",
    "            a.append(p_value.copy())\n",
    "        return a.copy()\n",
    "\n",
    "    def calculate_p_value(self,seperated_date,X_train):\n",
    "        p_value={label:self.summary_label(value) for label,value in seperated_date.items()}\n",
    "        return p_value\n",
    "\n",
    "    def train(self,X_train,y_train):\n",
    "        seperated_date=self.seperate_by_class(X_train,y_train)\n",
    "        self.p_label=self.p_label_calucate(seperated_date,X_train)\n",
    "        self.p_value=self.calculate_p_value(seperated_date)\n",
    "    \n",
    "    def predict(self,x):\n",
    "        p_label=self.p_label\n",
    "        p_value=self.p_value\n",
    "        max_label=0\n",
    "        max_p=0\n",
    "        for label in p_label:\n",
    "            p=p_label[label]\n",
    "            for i in range(len(x)):\n",
    "                p=p*p_value[label][i][x[i]]\n",
    "            if max_p<p:\n",
    "                max_p=p\n",
    "                max_label=label\n",
    "        print(max_label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bayes=model_lam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "naiveByes.train(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "naiveByes.predict([3,dict['S']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}